{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-17T05:30:30.526626Z","iopub.status.busy":"2024-02-17T05:30:30.526062Z","iopub.status.idle":"2024-02-17T05:30:58.212121Z","shell.execute_reply":"2024-02-17T05:30:58.211387Z","shell.execute_reply.started":"2024-02-17T05:30:30.526591Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-02-17 05:30:38.403138: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-02-17 05:30:38.403255: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-02-17 05:30:38.559167: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ed4fade187c4598acf3fd64b431364c","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7f4e410f382e446f8e0fe6f67a01b270","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b7cb146116743259bb8d902a30535af","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b25fe4f760a244298f8abf1a828686e9","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"906dbfc68d7144caa2fb34f2940768e1","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f5918bfc12e49ae91526160fd287f8d","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"data":{"text/plain":["[{'generated_text': \"Generate 3 Short, Unqiue and Good Legal Research title names on the legal query -'Siblings Murder'\"}]"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import pipeline, set_seed\n","generator = pipeline('text-generation', model='gpt2')\n","set_seed(42)\n","query=\"Siblings Murder\"\n","prompt = f\"Generate 3 Short, Unqiue and Good Legal Research title names on the legal query -'{query}'\"\n","generator(prompt, max_length=100)"]},{"cell_type":"markdown","metadata":{},"source":["## Enhance Facts"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-17T08:36:37.852879Z","iopub.status.busy":"2024-02-17T08:36:37.851975Z","iopub.status.idle":"2024-02-17T08:36:38.807936Z","shell.execute_reply":"2024-02-17T08:36:38.806979Z","shell.execute_reply.started":"2024-02-17T08:36:37.852840Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"data":{"text/plain":["[{'generated_text': \"Enhanced legal version of the fact -'Loan pending with the bank' with the addition of 2-5 words.\"}]"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["from transformers import pipeline, set_seed\n","generator = pipeline('text-generation', model='gpt2')\n","set_seed(42)\n","fact='Loan pending with the bank'\n","prompt = f\"Enhanced legal version of the fact -'{fact}' with the addition of 2-5 words.\"\n","generator(prompt, max_length=200)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
