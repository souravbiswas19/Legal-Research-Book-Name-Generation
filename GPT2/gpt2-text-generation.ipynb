{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import pipeline, set_seed\ngenerator = pipeline('text-generation', model='gpt2')\nset_seed(42)\nquery=\"Siblings Murder\"\nprompt = f\"Generate 3 Short, Unqiue and Good Legal Research title names on the legal query -'{query}'\"\ngenerator(prompt, max_length=100)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-17T05:30:30.526062Z","iopub.execute_input":"2024-02-17T05:30:30.526626Z","iopub.status.idle":"2024-02-17T05:30:58.212121Z","shell.execute_reply.started":"2024-02-17T05:30:30.526591Z","shell.execute_reply":"2024-02-17T05:30:58.211387Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-02-17 05:30:38.403138: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-02-17 05:30:38.403255: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-02-17 05:30:38.559167: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ed4fade187c4598acf3fd64b431364c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f4e410f382e446f8e0fe6f67a01b270"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b7cb146116743259bb8d902a30535af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b25fe4f760a244298f8abf1a828686e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"906dbfc68d7144caa2fb34f2940768e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f5918bfc12e49ae91526160fd287f8d"}},"metadata":{}},{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': \"Generate 3 Short, Unqiue and Good Legal Research title names on the legal query -'Siblings Murder'\"}]"},"metadata":{}}]},{"cell_type":"markdown","source":"## Enchance Facts","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline, set_seed\ngenerator = pipeline('text-generation', model='gpt2')\nset_seed(42)\nfact='Loan pending with the bank'\nprompt = f\"Enhanced legal version of the fact -'{fact}' with the addition of 2-5 words.\"\ngenerator(prompt, max_length=200)","metadata":{"execution":{"iopub.status.busy":"2024-02-17T08:36:37.851975Z","iopub.execute_input":"2024-02-17T08:36:37.852879Z","iopub.status.idle":"2024-02-17T08:36:38.807936Z","shell.execute_reply.started":"2024-02-17T08:36:37.852840Z","shell.execute_reply":"2024-02-17T08:36:38.806979Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': \"Enhanced legal version of the fact -'Loan pending with the bank' with the addition of 2-5 words.\"}]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}